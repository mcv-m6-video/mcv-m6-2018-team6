#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Sun Feb 25 23:54:17 2018

@author: yixiao
"""

#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
#--------------------------------------------------------------------
# M6 - Video Analysis: Video Surveillance for Road Traffic Monitoring
# Team06: YI XIAO, Juan Felipe Montesinos,Ferran Carrasquer

# week 1: Introduction, Databases, Evaluation Metrics

# This .py file is for defining some functions of evaluation
#--------------------------------------------------------------------
"""
import os
import numpy as np
from sklearn.metrics import precision_recall_fscore_support as PRFmetrics
from PIL import Image
import matplotlib.pyplot as plt
import cv2
import glob

# Input the folder path of the results and groundtruth, this function will output the precision, recall, f1_score for all the frames
def evaluateAllFrames(folder_path, gt_path):
    predVector = []
    trueVector = []
    if len(os.listdir(folder_path))==len(os.listdir(gt_path)):
        for filename in sorted(glob.glob(os.path.join(folder_path, 'test_*_00*.png'))):
            image = cv2.imread(filename,0)
            for ridx in range(image.shape[0]):
                for cidx in range(image.shape[1]):
                    predVector.append(image[ridx,cidx])
        for filename in sorted(glob.glob(os.path.join(gt_path, 'gt00*.png'))):
            gtImage = cv2.imread(filename,0)
            for ridx in range(gtImage.shape[0]):
                for cidx in range(gtImage.shape[1]):
                    trueVector.append(gtImage[ridx,cidx])
    else:
        print('The number of images are not corresponding!')
    trueArray = np.asarray(trueVector)
    predArray = np.asarray(predVector)        
    for j in range(len(trueArray)):
        if trueArray[j]==255:
            trueArray[j] = 1
        else:
            trueArray[j] = 0
    precision, recall,f1_score,support = PRFmetrics(trueArray, predArray, average='binary')
    return precision, recall, f1_score
    


# Input the pair of image and gt, this function will output the TP, FP, TN, FN
def evaluateOneFrame(frame,gt):
    predVector = []
    trueVector = []
    for p in range(0,frame.size):
        predVector.append(frame.flat[p])
    for p in range(0,gt.size):
        trueVector.append(gt.flat[p])
    trueArray = np.asarray(trueVector)
    predArray = np.asarray(predVector)     
    for i in range(len(trueArray)):
        if trueArray[i] == 255:
            trueArray[i] = 1
        else:
            trueArray[i] = 0
    _, _,f1_score_one,_ = PRFmetrics(trueArray, predArray, average='binary')  
    TP=0
    TN=0
    FP=0
    FN=0
    # for the gt, we only consider two classes(0,255) represent background and motion respectively.
    for j in range(len(trueArray)):
        # True Positive (TP): we predict a label of 255 is positive, and the gt is 255.
        if trueArray[j] == predArray[j] == 1:
            TP = TP+1
        # True Negative (TN): we predict a label of 0 is negative, and the gt is 0.
        if trueArray[j] == predArray[j] == 0:
            TN = TN+1
        # False Positive (FP): we predict a label of 255 is positive, but the gt is 0.
        if trueArray[j] ==0 and predArray[j] == 1:
            FP = FP+1
        # False Negative (FN): we predict a label of 0 is negative, but the gt is 255.
        if trueArray[j] == 1 and predArray[j] == 0:
            FN = FN+1      
    return TP, FN, f1_score_one

# This function is for evaluating the True Positive along time
def temproalTP(folder_path,gt_path):
    TF_list = []
    TP_list = []
    fileList = []
    gtList = []
    for filename in sorted(glob.glob(os.path.join(folder_path, 'test_*_00*.png'))):
        fileList.append(filename)
    for gtname in sorted(glob.glob(os.path.join(gt_path, 'gt00*.png'))):
        gtList.append(gtList)
    fileArray = np.asarray(fileList)
    gtArray = np.asarray(gtList) 
    for i in range(len(fileArray)):
        frame = cv2.imread(fileArray[i],0)
        gtImage = cv2.imread(gtArray[i],0)
        TP, FN, f1_score_frame = evaluateOneFrame(frame, gtImage)
        TotalForeground = TP + FN
        TP_list.append(TP)
        TF_list.append(TotalForeground)
    plt.plot(np.arange(len(TP_list)),TP_list,)
    plt.plot(np.arange(len(TF_list)),TF_list)
    plt.show()
       

# This function is for evaluating the F1-score along time
def temproalFscore(folder_path,gt_path):
    f1score_list = []
    fileList = []
    gtList = []
    for filename in sorted(glob.glob(os.path.join(folder_path, 'test_*_00*.png'))):
        fileList.append(filename)
    for gtname in sorted(glob.glob(os.path.join(gt_path, 'gt00*.png'))):
        gtList.append(gtList)
    fileArray = np.asarray(fileList)
    gtArray = np.asarray(gtList) 
    for i in range(len(fileArray)):
        frame = cv2.imread(fileArray[i],0)
        gtImage = cv2.imread(gtArray[i],0)
        _, _, f1_score_frame = evaluateOneFrame(frame, gtImage)
        f1score_list.append(f1_score_frame)
    plt.ylim(0.00,1.00)
    plt.plot(np.arange(len(f1score_list)),f1score_list)
    plt.show()
